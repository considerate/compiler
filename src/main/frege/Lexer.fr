module lexer.Lexer where
import Data.Monoid
import Control.Second(second)
import Data.List(find)
import Data.Char(isAlpha,isAlphaNum,isUpper,isDigit,isLower,isSpace)

-- Nicer looking function composition operator :)
infixr 3 ∘
f ∘ g = \x -> f (g x)

data Edges token = Edges [(Char -> Bool, Lexer (Char -> token))]
data State token = NonTerminal | Ignore | Terminal token
derive Eq (State token)
derive Show (State token)
data Lexer token = Lexer (State token) (Edges token)

instance Functor State where
    fmap _ NonTerminal = NonTerminal
    fmap _ Ignore = Ignore
    fmap f (Terminal token) = Terminal (f token)

instance Applicative State where
    pure = Terminal

    Terminal f <*> Terminal a = Terminal (f a)
    Ignore <*> _ = Ignore
    _ <*> Ignore = Ignore
    _ <*> _ = NonTerminal

instance Alt State where
    NonTerminal <|> result    = result
    result <|> NonTerminal    = result
    result <|> _       = result

instance Plus State where
    pzero = NonTerminal

instance Functor Edges where
    fmap f (Edges edges) = Edges $ map (second (fmap (f ∘))) edges

instance Monoid (Edges a) where
    mempty = Edges []

    (Edges as) `mappend` (Edges bs) = Edges (as <> bs)

instance Functor Lexer where
    fmap f (Lexer state edges) = Lexer (fmap f state) (fmap f edges)

applyToEdges :: Edges (a -> b) -> Lexer a -> Edges b
applyToEdges (Edges edges) xs = Edges $ fmap (second (\next -> fmap flip next <*> xs)) edges

instance Applicative Lexer where
    pure token = Lexer (pure token) (Edges [])

    Lexer NonTerminal edges <*> xs =
        Lexer NonTerminal (applyToEdges edges xs)

    Lexer Ignore edges <*> xs =
        Lexer Ignore (applyToEdges edges xs)

    --Map all functions from fs onto all values from xs
    Lexer (Terminal f) fedges <*> xs@(Lexer xstate xedges) =
        Lexer (pure f <*> xstate) (fmap f xedges <> applyToEdges fedges xs)

instance Alt Lexer where
    Lexer state edges <|> Lexer state' edges' =
        Lexer (state <|> state') (edges <> edges')

instance Plus Lexer where
    pzero = Lexer NonTerminal (Edges [])

many :: (Applicative f, Plus f) => f a -> f [a]
many !v = many_v
    where
        -- same definition as for some causes:
        -- ClassCastException: BlackHole cannot be cast to Lexer$TLexer
        many_v = (fmap (:) v <*> many_v) <|> pure []

some :: (Applicative f, Plus f) => f a -> f [a]
some !v = some_v
    where
        many_v = (fmap (:) v <*> many_v) <|> pure []
        some_v = (fmap (:) v) <*> many_v


ignore :: Lexer b
ignore = Lexer Ignore (Edges [])

satisfy :: (Char -> Bool) -> Lexer Char
satisfy predicate = Lexer NonTerminal (Edges [(predicate, pure id)])

char :: Char -> Lexer Char
char c = satisfy (==c)

string :: String -> Lexer [Char]
string = string' . unpacked

string' :: [Char] -> Lexer [Char]
string' [] = pure []
string' (c:cs) = fmap (:) (char c) <*> string' cs

pair :: Lexer a -> Lexer b -> Lexer (a,b)
pair a b = fmap (,) a <*> b

pairWith :: (a -> b -> c) -> Lexer a -> Lexer b -> Lexer c
pairWith f a b = fmap f a <*> b

digit :: Lexer Char
digit = satisfy isDigit

upper :: Lexer Char
upper = satisfy isUpper

lower :: Lexer Char
lower = satisfy isLower

letter :: Lexer Char
letter = satisfy isAlpha

alphanumeric :: Lexer Char
alphanumeric = satisfy isAlphaNum

space :: Lexer Char
space = char ' ' <|> char '\n'

type Position = (Int, Int)
data Lexeme a = Bad Position | Ok Position a | EOF Position
derive Show (Lexeme a)

getNextLexer :: Edges a -> Char -> Maybe (Lexer (Char -> a))
getNextLexer (Edges edges) c = fmap snd (find (`fst` c) edges)

stepPosition :: Char -> Position -> Position
stepPosition '\n' (line, _) = (line+1,1)
stepPosition _ (line, col) = (line, col+1)

scan :: (Show a) => Lexer a -> Position -> [Char] -> (State a, [Char], Position)
scan lexer startPos startInput = consume lexer startPos startInput (NonTerminal, startInput, startPos)
    where
        consume (Lexer state edges) pos input lastScan =
            let currentScan = nextScan state
            in case input of
                [] -> currentScan
                (c:cs) -> case getNextLexer edges c of
                    Nothing -> currentScan
                    Just next -> consume (next <*> pure c) (stepPosition c pos) cs currentScan
            where
                nextScan NonTerminal = lastScan
                nextScan _ = (state, input, pos)

checkPrefix :: [Char] -> Position -> [Lexeme a] -> [Lexeme a]
checkPrefix prefix pos lexemes = case prefix of
    [] -> lexemes
    _ -> Bad pos : lexemes

initialPosition :: Position
initialPosition = (1,1)

runLexer :: (Show a) => Lexer a -> [Char] -> [Lexeme a]
runLexer lexer = tokenize (initialPosition, initialPosition) []
    where
        -- tokenize :: (Position, Position) -> String -> String -> [Lexeme a]
        tokenize (pos, errPos) prefix input
            | traceLn (show input) = undefined
            | otherwise =
                let scanned = scan lexer pos input
                in if (traceLn (show scanned)) then undefined
                else case scanned of
                    --EOF
                    (NonTerminal, [], pos') -> checkPrefix prefix errPos [EOF pos']
                    --För att fortsätta när man hittar en BAD:
                    (NonTerminal, c:input', pos') -> tokenize (stepPosition c pos', errPos) (c:prefix) input'
                    --Hittat en token. Kolla prefix och lexa resten.
                    (Terminal token, input', pos') ->  checkPrefix prefix errPos $ Ok pos token : tokenize (pos', pos') [] input'
                    --Hittat en ignore. Kolla prexif och lexa resten.
                    (Ignore, input', pos') -> checkPrefix prefix errPos $ tokenize (pos', pos') [] input'

isOk lexeme = case lexeme of
    Ok _ _ -> true
    _ -> false

ofOk (Ok _ x) = x
ofOk (Bad _) = error "Did not get a valid token"
ofOk (EOF _) = error "Did not get a valid token"

toValidTokens :: [Lexeme a] -> [a]
toValidTokens = map ofOk . filter (isOk)
