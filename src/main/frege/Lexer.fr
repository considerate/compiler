module lexer.Lexer where
import Data.Monoid
import Control.Second(second)
import Data.List(find)
import Data.Char(isAlpha,isAlphaNum,isUpper,isDigit,isLower)

-- Nicer looking function composition operator :)
infixr 3 ∘
f ∘ g = \x -> f (g x)

data Edges token = Edges [(Char -> Bool, Lexer (Char -> token))]
data State token = NonTerminal | Ignore | Terminal token
derive Eq (State token)
derive Show (State token)
data Lexer token = Lexer (State token) (Edges token)

instance Functor State where
    fmap _ NonTerminal = NonTerminal
    fmap _ Ignore = Ignore
    fmap f (Terminal token) = Terminal (f token)

instance Applicative State where
    pure = Terminal

    Terminal f <*> Terminal a = Terminal (f a)
    _ <*> _ = NonTerminal

instance Alt State where
    NonTerminal <|> result    = result
    result <|> NonTerminal    = result
    result <|> _       = result

instance Plus State where
    pzero = NonTerminal

instance Functor Edges where
    fmap f (Edges edges) = Edges $ map (second (fmap (f ∘))) edges

instance Monoid (Edges a) where
    mempty = Edges []

    (Edges as) `mappend` (Edges bs) = Edges (as <> bs)

instance Functor Lexer where
    fmap f (Lexer state edges) = Lexer (fmap f state) (fmap f edges)

applyToEdges :: Edges (a -> b) -> Lexer a -> Edges b
applyToEdges (Edges edges) xs = Edges $ fmap (second (\next -> fmap flip next <*> xs)) edges

instance Applicative Lexer where
    pure token = Lexer (pure token) (Edges [])

    Lexer NonTerminal edges <*> xs =
        Lexer NonTerminal (applyToEdges edges xs)

    Lexer Ignore edges <*> xs =
        Lexer Ignore (applyToEdges edges xs)

    --Map all functions from fs onto all values from xs
    Lexer (Terminal f) fedges <*> xs@(Lexer xstate xedges) =
        Lexer (pure f <*> xstate) (fmap f xedges <> applyToEdges fedges xs)

instance Alt Lexer where
    Lexer state edges <|> Lexer state' edges' =
        Lexer (state <|> state') (edges <> edges')

instance Plus Lexer where
    pzero = Lexer NonTerminal (Edges [])

many :: (Applicative f, Plus f) => f a -> f [a]
many !v = many_v
    where
        -- same definition as for some causes:
        -- ClassCastException: BlackHole cannot be cast to Lexer$TLexer
        many_v = (fmap (:) v <*> many_v) <|> pure []

some :: (Applicative f, Plus f) => f a -> f [a]
some !v = some_v
    where
        many_v = some_v <|> pure []
        some_v = (fmap (:) v) <*> many_v

ignore :: Lexer a
ignore = Lexer Ignore (Edges [])

satisfy :: (Char -> Bool) -> Lexer Char
satisfy predicate = Lexer NonTerminal (Edges [(predicate, pure id)])

char :: Char -> Lexer Char
char c = satisfy (==c)

string :: [Char] -> Lexer [Char]
string [] = pure []
string (c:cs) = fmap (:) (char c) <*> string cs

pair :: Lexer a -> Lexer b -> Lexer (a,b)
pair a b = fmap (,) a <*> b

pairWith :: (a -> b -> c) -> Lexer a -> Lexer b -> Lexer c
pairWith f a b = fmap f a <*> b

digit :: Lexer Char
digit = satisfy isDigit

upper :: Lexer Char
upper = satisfy isUpper

lower :: Lexer Char
lower = satisfy isLower

letter :: Lexer Char
letter = satisfy isAlpha

alphanumeric :: Lexer Char
alphanumeric = satisfy isAlphaNum

type Position = Int
data Lexeme a = Bad Position | Ok Position a | EOF
derive Show (Lexeme a)

getNextLexer :: Edges a -> Char -> Maybe (Lexer (Char -> a))
getNextLexer (Edges edges) c = fmap snd (find (`fst` c) edges)

scan :: Lexer a -> Position -> [Char] -> (State a, [Char], Position)
scan lexer startPos startInput = consume lexer startPos startInput (NonTerminal, startInput, startPos)
    where
        consume (Lexer state edges) pos input lastScan =
            let currentScan = nextScan state
            in case input of
                [] -> currentScan
                (c:cs) -> case getNextLexer edges c of
                    Nothing -> currentScan
                    Just next -> consume (next <*> pure c) (pos+1) cs currentScan
            where
                nextScan NonTerminal = lastScan
                nextScan _ = (state, input, pos)

checkPrefix :: [Char] -> Position -> [Lexeme a] -> [Lexeme a]
checkPrefix prefix pos lexemes = case prefix of
    [] -> lexemes
    _ -> Bad pos : lexemes

initialPosition :: Position
initialPosition = 0

runLexer :: Lexer a -> [Char] -> [Lexeme a]
runLexer lexer = tokenize (initialPosition, initialPosition) []
    where
        -- tokenize :: (Position, Position) -> String -> String -> [Lexeme a]
        tokenize (pos, errPos) prefix input =
            case scan lexer pos input of
                (NonTerminal, [], _) -> checkPrefix prefix errPos [] ++ [EOF]
                (NonTerminal, c:input', pos') -> tokenize (pos'+1, errPos) (c:prefix) input'
                (Terminal token, input', pos') ->  checkPrefix prefix errPos $ Ok pos token : tokenize (pos', pos') [] input'
                (Ignore, input', pos') -> checkPrefix prefix errPos $ tokenize (pos', pos') [] input'
